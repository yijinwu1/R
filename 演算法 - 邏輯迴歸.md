# 邏輯迴歸

*   乙狀函數為一介於(0,1)之間，嚴格遞增的可微分函數
> ![ubuntu1](../master/images/LR1.png)

*   使用乙狀函數描述解釋變數X與條件機率的關係
![ubuntu1](../master/images/LR2.png)

* 為什麼要取對數勝率(Log Odds，又稱Logit)? 對數勝率(Log Odds/Logit)與機率呈現乙狀關係
  * 解釋變數與條件機率呈現乙狀關係(邏輯迴歸的基本假設)
  * 對數勝率與條件機率呈現乙狀關係(對數勝率的數學性質)
> ![ubuntu1](../master/images/LR3.png)

*   利用最大概似法估計邏輯迴歸的參數
> ![ubuntu1](../master/images/LR4.png)

*   假設檢定:確認參數是否顯著異於0
> ![ubuntu1](../master/images/LR5.png)

<table>
    <tr>
        <td colspan="4">解釋變數增加1單位將影響對數勝率、勝率、條件機率</td>	
	</tr>
    <tr>
        <td colspan="4">logit = β0 + β1X1</td>	
	</tr>	
    <tr>
	    <td></td>
        <td>對數勝率Logit</td>	 
        <td>勝率Odds</td>
		<td>P(Y=1 | X1)</td>
    </tr>	
    <tr>
	    <td>數值</td>
        <td>正比β1</td>	 
        <td>正比β1</td>
		<td>正比β1</td>
    </tr>		
</table>

<table>
    <tr>
        <td colspan="4">透過量化指標或是統計檢定進行模型比較</td>	
	</tr>
    <tr>
	    <td></td>
        <td>Pseudo R-Square</td>	 
        <td>AIC / BIC</td>
		<td>極度比檢定</td>
    </tr>	
    <tr>
	    <td>理論</td>
        <td>比較目前模型與模型1兩種模型捕捉資料資訊的能力</td>	 
        <td>計算目前模型與真實模型時的資訊落差，同時對遍數量進懲罰</td>
		<td>比較兩個不同模型(不同解釋變數X)捕捉資料資訊的能力</td>
    </tr>
    <tr>
	    <td>說明</td>
        <td>越靠近1，代表模型的解釋能力越好</td>	 
        <td>AIC / BIC越小，資訊落差越小，解釋能力越好</td>
		<td>若結果顯著，代表傾向接受第一個模型</td>
    </tr>	
</table>

*   估計完個體機率後，根據設定的臨界機率進行分類
> ![ubuntu1](../master/images/LR6.png)

<table>
    <tr>
        <td colspan="4">分類問題的模糊矩陣(Confusion Matrix)</td>	
	</tr>
    <tr>
	    <td></td>
		<td></td>
        <td colspan="2">真實情況</td>	 
    </tr>	
    <tr>
	    <td></td>
		<td></td>	
        <td>Y=1</td>	 
        <td>Y=0</td>
    </tr>	
    <tr>
	    <td rowspan="2">模型分類</td>
        <td>Y=1</td>	 
        <td>真陽性TP<br>(True Positive)</td>
		<td>偽陽性FP<br>(False Positive)</td>
    </tr>
    <tr>
        <td>Y=0</td>	 
        <td>偽陰性FN<br>(False Negative)</td>
		<td>真陰性TN<br>(True Negative)</td>
    </tr>	
</table> 
 
* 準確率(Accuracy)
  * 指標定義:所有個體中，有多少比率的個體被分類正確?
  * 計算公式:Accuracy = (TP + TN) / (TP + FP + TN + FN)
* 精確度(Precision)
  * 指標定義:被模型分類為陽性的個體中，有多少比率確實為陽性?
  * 計算公式:Precision = TP / (TP + FP)
* 召回度/敏感度(Recall/Sensitivity)
  * 指標定義:真正為陽性的個體中，有多少模型正確分類為陽性?
  * 計算公式:Recall = TP / (TP + FN) 
* 明確度(Specificity)
  * 指標定義:被模型分類為陰性的個體中，有多少比率確實為陰性?
  * 計算公式:Specificity = TN / (TN + FP) 
  
* 解釋ROC曲線(敏感度與明確度間的抵換關係) 
  * 由左而右代表臨界機率從1至0的到的(1-明確度,敏感度)
  * 曲線下面積(AUC)越靠近1，代表模型的分類效果越好，估計出來的機率越能夠分開資料
> ![ubuntu1](../master/images/LR7.png)  
