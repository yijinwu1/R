# 決策樹
*   不只要判斷清楚，也需要清楚的決策過程
<table>
    <tr>
        <td></td>	 
        <td>判斷清楚</td>
		<td>決策過程</td>
    </tr>	
    <tr>
        <td>目的</td>	 
        <td>衡量新納入的變數能不能幫助我們判斷的更清楚，<br>包含分類問題、預測問題等</td>
		<td>表達不同爭對於判斷目標的貢獻度與關係</td>
    </tr>
    <tr>
        <td>方法</td>	 
        <td>再引入不同特徵後，計算不確定性，<br>用來衡量是否能判斷得更清楚</td>
		<td>進一步將將地步確定性的過程視覺化</td>
    </tr>	
	<tr>
        <td>解決方案</td>	 
        <td colspan="2">考量原始資料的各個特徵，並計算目前的不確定性<br>計算加入不同的變數後，是否能降低判斷的不確定性<br>找出判斷正確可能性最大的幾種決策路徑</td>
    </tr>
</table>
<hr/>
吉尼不純度Gini Impurity : 衡量納入新特徵後能否降低不確定程度

> ![ubuntu1](../master/images/tree1.png)

* 步驟
  * Step 1:選取一個或多個特徵，並計算吉尼不純度
  * Step 2:和選取前一次的結果做比較
  * Step 3:重複前兩個步驟直到吉尼布純度不能下降為止
<hr/>  
熵 : 衡量現有資訊的複雜(混亂)程度

> ![ubuntu1](../master/images/tree2.png)

* 步驟
  * Step 1:選取一個或多個特徵，並計算熵
  * Step 2:和選取前一次的結果做比較
  * Step 3:重複前兩個步驟直到熵下降為止
  
<table>
    <tr>
        <td colspan="3">吉尼不純度與熵比較(以不同觀點衡量不確定性)</td>
    </tr>
    <tr>
        <td></td>	 
        <td>吉尼不純度</td>
		<td>熵</td>
    </tr>	
    <tr>
        <td>原理</td>	 
        <td>以判斷結果是否區分清楚，降低不純度，來衡量特徵對於判斷目標的幫助</td>
		<td>以資訊的複雜度出發，探討新的特徵能否降低整體複雜度，進而更容易判斷</td>
    </tr>
    <tr>
        <td>強調</td>	 
        <td>強調直觀理解判斷結果的</td>
		<td>強調每次結果的資訊複雜度</td>
    </tr>	
	<tr>
        <td>計算方式</td>	 
        <td><img src="https://github.com/yijinwu1/R/blob/master/images/tree3.png"></td>
        <td><img src="https://github.com/yijinwu1/R/blob/master/images/tree3.png"></td>
    </tr>
    <tr>
        <td colspan="3">資訊增益 Information Gain<br>計算這兩個指標的過程中，下降多少不確定性，增加了多少有用的資訊</td>
    </tr>	
</table>
<hr/>
*   CART:由上而下建構的二分岔樹，讓不確定性或誤差平方最小

> ![ubuntu1](../master/images/tree5.png)  

* CART流程
  * Step 1:比較不同特徵的分類效果，以指標最小的特徵做為起點進行分岔
  * Step 2:針對分岔後的各節點，繼續納入新的特徵進行分岔
  * Step 3:若新的特徵無法使判斷指標繼續下降，則停止於該節點分岔
  * Step 4:衡量整個模型的不確定性或誤差平方，直到無法再降低為止
  * Step 5:保留現有結構，做為決策樹模型   

> ![ubuntu1](../master/images/tree6.png) 

> ![ubuntu1](../master/images/tree7.png) 

<hr/>
<table>
    <tr>
        <td colspan="2">過度擬合與剪枝</td>	 
    </tr>	
    <tr>
        <td colspan="2">過度擬合(Over-fitting)</td>	 
    </tr>
    <tr>
        <td>說明</td>	 
        <td>決策樹模型為了配合目前觀察到的資料型態，而過度生長(過度複雜)；雖然能夠精準分類、預測現有資料，卻沒辦法提供正確的洞察，或應用在其他資料集上</td>
    </tr>
    <tr>
        <td colspan="2">剪枝(Prune)</td>	 
    </tr>	
	<tr>
        <td>說明</td>	 
        <td>修剪過度生長的分支</td>
    </tr>
	<tr>
        <td>方法</td>	 
        <td>交叉驗證:用訓練和驗證資料重複檢測<br>統計檢測:檢驗是否在整體資料具有統計上的顯著差異<br>衡量指標:如REP、PEP、CCP等指標，計算是否應該剪枝</td>
    </tr>	
</table> 
