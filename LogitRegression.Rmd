---
title: "邏輯迴歸"
author: "wuyijin"
date: "2019年2月1日"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<h1>邏輯迴歸</h1>
*   是與否的問題
    * 建立影響因素(X)與「是/否」(Y)的關係
    * 透過「條件機率」連結「影響因素」(X)與「是/否」(Y) 
        * 機率的好處：完全相同的情境，也可能會有不同的結果
    * 透過大量個體資料，分析解釋變數如何影響是與否決策        
*   乙狀函數 - 描述X與Y的關係
    * 為一介於(0,1)之間，嚴格遞增的可微分函數
        * ![image](https://yijinwu1.github.io/R/images/LR1.png)
    * 使用乙狀函數描述解釋變數X與條件機率的關係
        * ![image](https://yijinwu1.github.io/R/images/LR2.png) 
    * 勝率(Odds)代表成功機率與失敗機率的比值  
        * ![image](https://yijinwu1.github.io/R/images/LR8.png)
    * 對數勝率(Log Odds/Logit)與機率呈現乙狀關係
        * ![image](https://yijinwu1.github.io/R/images/LR3.png)
        * 解釋變數與條件機率呈現乙狀關係(邏輯迴歸的基本假設)
        * 對數勝率與條件機率呈現乙狀關係(對數勝率的數學性質)  
        * 對數勝率與解釋變數呈現線性關係，且logit可為負，因此可以線性表達        
<hr/>
*   最大概似法
    * 利用最大概似法估計邏輯迴歸的參數
    * ![image](https://yijinwu1.github.io/R/images/LR4.png)
*   多元邏輯回歸模型：變數與待估計參數增加
    * ![image](https://yijinwu1.github.io/R/images/LR9.png)
    * 如何確認是否β's是否顯著不為0?
        *   假設檢定
            * 確認參數是否顯著異於0
              ![image](https://yijinwu1.github.io/R/images/LR5.png)    
            * 解釋變數增加1單位將影響對數勝率、勝率、條件機率
<table BORDER="2">
  <tr>
    <td ALIGN=center colspan="4">logit = β0 + β1X1</td>
  </tr>
  <tr>
    <td></td>
    <td ALIGN=left>&nbsp;對數勝率(Logit)&nbsp;</td>
    <td ALIGN=left>&nbsp;勝率(Odds)&nbsp;</td>
    <td ALIGN=left>&nbsp;P(Y=1|X1)&nbsp;</td>
  </tr>
  <tr>
    <td ALIGN=left>&nbsp;數值&nbsp;</td>
    <td ALIGN=left>&nbsp;正比β1</td>
    <td ALIGN=left>&nbsp;正比β1</td>
    <td ALIGN=left>&nbsp;正比β1</td>
  </tr>
</table>
<hr/>

    * 如何比較使用不同解釋變數X's的模型?
        *   透過量化指標或是統計檢定進行模型比較
<table BORDER="2">
  <tr>
    <td></td>
    <td>&nbsp;Pseudo R-Square&nbsp;</td>
    <td>&nbsp;AIC / BIC&nbsp;</td>
    <td>&nbsp;極度比檢定&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;理論&nbsp;</td>
    <td>&nbsp;比較目前模型與模型1<br>&nbsp;兩種模型捕捉資料資訊的能力&nbsp;</td>
    <td>&nbsp;計算目前模型與真實模型時的<br>&nbsp;資訊落差，同時對變數量進懲罰&nbsp;</td>
    <td>&nbsp;比較兩個不同模型(不同解釋變數X)<br>&nbsp;捕捉資料資訊的能力&nbsp;</td>
  </tr>
  <tr>
    <td>&nbsp;說明&nbsp;</td>
    <td>&nbsp;越靠近1，<br>&nbsp;代表模型的解釋能力越好&nbsp;</td>
    <td>&nbsp;AIC/BIC越小，<br>&nbsp;資訊落差越小，解釋能力越好&nbsp;</td>
    <td>&nbsp;若結果顯著，<br>&nbsp;代表傾向接受第一個模型&nbsp;</td>
  </tr>	  
</table>
<hr/>
*   估計完個體機率後，根據設定的臨界機率進行分類
    * ![image](https://yijinwu1.github.io/R/images/LR6.png)
*   分類問題的模糊矩陣(Confusion Matrix)
    * ![image](https://yijinwu1.github.io/R/images/LR10.png)
        * 準確率(Accuracy)：衡量模型分類正確率
            * ![image](https://yijinwu1.github.io/R/images/LR11.png)
            * 指標定義:所有個體中，有多少比率的個體被分類正確?
            * 計算公式:Accuracy = (TP + TN) / (TP + FP + TN + FN)
        * 精確度(Precision)：避免模型誤判個體為陽性
            * ![image](https://yijinwu1.github.io/R/images/LR12.png)
            * 指標定義:被模型分類為陽性的個體中，有多少比率確實為陽性?
            * 計算公式:Precision = TP / (TP + FP)
        * 召回度/敏感度(Recall/Sensitivity)：避免錯過任何一個陽性個體
            * ![image](https://yijinwu1.github.io/R/images/LR13.png)        
            * 指標定義:真正為陽性的個體中，有多少模型正確分類為陽性?
            * 計算公式:Recall = TP / (TP + FN) 
        * 明確度(Specificity)：能夠準確分辨出陰性個體
            * ![image](https://yijinwu1.github.io/R/images/LR14.png)        
            * 指標定義:被模型分類為陰性的個體中，有多少比率確實為陰性?
            * 計算公式:Specificity = TN / (TN + FP)
        * 解釋ROC曲線(隨著臨界機率的調整，敏感度與明確度間存在抵換關係)
            * ![image](https://yijinwu1.github.io/R/images/LR7.png)
            * 由左而右代表臨界機率從1至0得到的(1-明確度,敏感度)
            * 曲線下面積(AUC)越靠近1，代表模型的分類效果越好，估計出來的機率越能夠分開資料
<hr/>